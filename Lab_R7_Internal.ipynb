{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_R7_Internal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YeoiMbH7djEv"
      },
      "source": [
        "# Stock prices dataset\n",
        "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
        "\n",
        "## Description\n",
        "A brief description of columns.\n",
        "- open: The opening market price of the equity symbol on the date\n",
        "- high: The highest market price of the equity symbol on the date\n",
        "- low: The lowest recorded market price of the equity symbol on the date\n",
        "- close: The closing recorded price of the equity symbol on the date\n",
        "- symbol: Symbol of the listed company\n",
        "- volume: Total traded volume of the equity symbol on the date\n",
        "- date: Date of record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RSoYY2nII_UW"
      },
      "source": [
        "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGqq9f8VdLba",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_88voqAH-O6J"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dRHCeJqP-evf"
      },
      "source": [
        "### Load the data\n",
        "- load the csv file and read it using pandas\n",
        "- file name is prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cKVH5v7r-RmC",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bdf31619-96e3-489e-e26e-adc4d781f85c"
      },
      "source": [
        "# run this cell to upload file using GUI if you are using google colab\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a4ae6e9-1a78-4e15-89d5-d5fbbbfa3882\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a4ae6e9-1a78-4e15-89d5-d5fbbbfa3882\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gr4YcffYd1FQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "564a4cf5-fa25-445c-a32b-74863459b875"
      },
      "source": [
        "# run this cell to to mount the google drive if you are using google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-DJM0HIKYyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/ColabNotebooks/prices.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HlLKVPVH_BCT"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZxoGynuBeO4t"
      },
      "source": [
        "### Drop null\n",
        "- Drop null values if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yuwJJIeeUaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "16f94eb7-524b-4f4f-b4b1-4247d854a166"
      },
      "source": [
        "df.dropna()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851259</th>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>ZBH</td>\n",
              "      <td>103.309998</td>\n",
              "      <td>103.199997</td>\n",
              "      <td>102.849998</td>\n",
              "      <td>103.930000</td>\n",
              "      <td>973800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851260</th>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>ZION</td>\n",
              "      <td>43.070000</td>\n",
              "      <td>43.040001</td>\n",
              "      <td>42.689999</td>\n",
              "      <td>43.310001</td>\n",
              "      <td>1938100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851261</th>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>ZTS</td>\n",
              "      <td>53.639999</td>\n",
              "      <td>53.529999</td>\n",
              "      <td>53.270000</td>\n",
              "      <td>53.740002</td>\n",
              "      <td>1701200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851262</th>\n",
              "      <td>2016-12-30 00:00:00</td>\n",
              "      <td>AIV</td>\n",
              "      <td>44.730000</td>\n",
              "      <td>45.450001</td>\n",
              "      <td>44.410000</td>\n",
              "      <td>45.590000</td>\n",
              "      <td>1380900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851263</th>\n",
              "      <td>2016-12-30 00:00:00</td>\n",
              "      <td>FTV</td>\n",
              "      <td>54.200001</td>\n",
              "      <td>53.630001</td>\n",
              "      <td>53.389999</td>\n",
              "      <td>54.480000</td>\n",
              "      <td>705100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>851264 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date symbol  ...        high     volume\n",
              "0       2016-01-05 00:00:00   WLTW  ...  126.250000  2163600.0\n",
              "1       2016-01-06 00:00:00   WLTW  ...  125.540001  2386400.0\n",
              "2       2016-01-07 00:00:00   WLTW  ...  119.739998  2489500.0\n",
              "3       2016-01-08 00:00:00   WLTW  ...  117.440002  2006300.0\n",
              "4       2016-01-11 00:00:00   WLTW  ...  117.330002  1408600.0\n",
              "...                     ...    ...  ...         ...        ...\n",
              "851259           2016-12-30    ZBH  ...  103.930000   973800.0\n",
              "851260           2016-12-30   ZION  ...   43.310001  1938100.0\n",
              "851261           2016-12-30    ZTS  ...   53.740002  1701200.0\n",
              "851262  2016-12-30 00:00:00    AIV  ...   45.590000  1380900.0\n",
              "851263  2016-12-30 00:00:00    FTV  ...   54.480000   705100.0\n",
              "\n",
              "[851264 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9J4BlzVA_gZd"
      },
      "source": [
        "### Drop columns\n",
        "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
        "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKEK8aEE_Csx",
        "colab": {}
      },
      "source": [
        "df.drop(['date','volume','symbol'],axis=1,inplace=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cTPhO6v-AiZt"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SsZXmF3NAkna"
      },
      "source": [
        "### Print the dataframe\n",
        "- print the modified dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aKs04iIHAjxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "4bb306f9-ca15-44eb-b633-6c7562163b10"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          open       close         low        high\n",
              "0   123.430000  125.839996  122.309998  126.250000\n",
              "1   125.239998  119.980003  119.940002  125.540001\n",
              "2   116.379997  114.949997  114.930000  119.739998\n",
              "3   115.480003  116.620003  113.500000  117.440002\n",
              "4   117.010002  114.970001  114.089996  117.330002\n",
              "5   115.510002  115.550003  114.500000  116.059998\n",
              "6   116.459999  112.849998  112.589996  117.070000\n",
              "7   113.510002  114.379997  110.050003  115.029999\n",
              "8   113.330002  112.529999  111.919998  114.879997\n",
              "9   113.660004  110.379997  109.870003  115.870003\n",
              "10  109.059998  109.300003  108.320000  111.599998\n",
              "11  109.730003  110.000000  108.320000  110.580002\n",
              "12  111.879997  111.949997  110.190002  112.949997\n",
              "13  111.320000  110.120003  110.000000  114.629997\n",
              "14  110.419998  111.000000  107.300003  111.400002\n",
              "15  110.769997  110.709999  109.019997  112.570000\n",
              "16  110.900002  112.580002  109.900002  112.970001\n",
              "17  113.349998  114.470001  111.669998  114.589996\n",
              "18  114.000000  114.500000  112.900002  114.849998\n",
              "19  113.250000  110.559998  109.750000  113.860001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8u_jlbABTip"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
        "- Take \"open\" \"low\", \"high\" columns as features\n",
        "- Take \"close\" column as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQjCMzUXBJbg",
        "colab": {}
      },
      "source": [
        "y = df['close']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUXHepuKNy9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df.drop('close',axis=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6vGtnapgBIJm"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8pZAKdJ5gcrm"
      },
      "source": [
        "### Create train and test sets\n",
        "- Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KalRqA6Rgqsn",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 7)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aTAKzlxZBz0z"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O7BU2qxEg0Ki"
      },
      "source": [
        "### Scaling\n",
        "- Scale the data (features only)\n",
        "- Use StandarScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AcO8SlhPhBkR",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upZH2P4dPwoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.fit(X_train)\n",
        "scaledX_train = scaler.transform(X_train)\n",
        "scaledX_test = scaler.transform(X_test)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3TWpN0nVTpUx"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sj0LYNkhR-L"
      },
      "source": [
        "### Convert data to NumPy array\n",
        "- Convert features and labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X6mIfuTxhbTT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diqsjjvDTbyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = np.array(y_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmXUGc2oTspa"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cl2M9whFh6mh"
      },
      "source": [
        "### Define Model\n",
        "- Initialize a Sequential model\n",
        "- Add a Flatten layer\n",
        "- Add a Dense layer with one neuron as output\n",
        "  - add 'linear' as activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TkiBpORmiegL",
        "colab": {}
      },
      "source": [
        "X_train = scaledX_train.reshape(scaledX_train.shape[0], scaledX_train.shape[1], 1)\n",
        "X_test = scaledX_test.reshape(scaledX_test.shape[0], scaledX_test.shape[1], 1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E463gRzHePlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, Reshape, Flatten, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Reshape((X_train.shape[0],X_train.shape[1],1)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense (1, activation='linear'))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8a0wr94aTyjg"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BNZPb5lKioX0"
      },
      "source": [
        "### Compile the model\n",
        "- Compile the model\n",
        "- Use \"sgd\" optimizer\n",
        "- for calculating loss, use mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEQUP3VaiuT2",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "model.compile(optimizer = 'sgd', loss='mean_squared_error' , metrics=['mse'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbBpnOtfT0wd"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9o45OHdjDhA"
      },
      "source": [
        "### Fit the model\n",
        "- epochs: 50\n",
        "- batch size: 128\n",
        "- specify validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Y6tA30XjOH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b81fb370-0845-4a96-8bfc-9f6244a3cb04"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 128, epochs = 50)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 36.9162 - mse: 36.9162\n",
            "Epoch 2/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9810 - mse: 0.9810\n",
            "Epoch 3/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9730 - mse: 0.9730\n",
            "Epoch 4/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9637 - mse: 0.9637\n",
            "Epoch 5/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9570 - mse: 0.9570\n",
            "Epoch 6/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9484 - mse: 0.9484\n",
            "Epoch 7/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9433 - mse: 0.9433\n",
            "Epoch 8/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9343 - mse: 0.9343\n",
            "Epoch 9/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9251 - mse: 0.9251\n",
            "Epoch 10/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9196 - mse: 0.9196\n",
            "Epoch 11/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.9119 - mse: 0.9119\n",
            "Epoch 12/50\n",
            "5321/5321 [==============================] - 7s 1ms/step - loss: 0.9063 - mse: 0.9063\n",
            "Epoch 13/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8990 - mse: 0.8990\n",
            "Epoch 14/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8924 - mse: 0.8924\n",
            "Epoch 15/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8840 - mse: 0.8840\n",
            "Epoch 16/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8770 - mse: 0.8770\n",
            "Epoch 17/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8713 - mse: 0.8713\n",
            "Epoch 18/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8657 - mse: 0.8657\n",
            "Epoch 19/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8600 - mse: 0.8600\n",
            "Epoch 20/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8531 - mse: 0.8531\n",
            "Epoch 21/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8462 - mse: 0.8462\n",
            "Epoch 22/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8400 - mse: 0.8400\n",
            "Epoch 23/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8334 - mse: 0.8334\n",
            "Epoch 24/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8284 - mse: 0.8284\n",
            "Epoch 25/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8239 - mse: 0.8239\n",
            "Epoch 26/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8180 - mse: 0.8180\n",
            "Epoch 27/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8116 - mse: 0.8116\n",
            "Epoch 28/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8053 - mse: 0.8053\n",
            "Epoch 29/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.8000 - mse: 0.8000\n",
            "Epoch 30/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7942 - mse: 0.7942\n",
            "Epoch 31/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7891 - mse: 0.7891\n",
            "Epoch 32/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7849 - mse: 0.7849\n",
            "Epoch 33/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7799 - mse: 0.7799\n",
            "Epoch 34/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7750 - mse: 0.7750\n",
            "Epoch 35/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7707 - mse: 0.7707\n",
            "Epoch 36/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7649 - mse: 0.7649\n",
            "Epoch 37/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7607 - mse: 0.7607\n",
            "Epoch 38/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7543 - mse: 0.7543\n",
            "Epoch 39/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7498 - mse: 0.7498\n",
            "Epoch 40/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7450 - mse: 0.7450\n",
            "Epoch 41/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7410 - mse: 0.7410\n",
            "Epoch 42/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7360 - mse: 0.7360\n",
            "Epoch 43/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7314 - mse: 0.7314\n",
            "Epoch 44/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7263 - mse: 0.7263\n",
            "Epoch 45/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7235 - mse: 0.7235\n",
            "Epoch 46/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7187 - mse: 0.7187\n",
            "Epoch 47/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7151 - mse: 0.7151\n",
            "Epoch 48/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7093 - mse: 0.7093\n",
            "Epoch 49/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7059 - mse: 0.7059\n",
            "Epoch 50/50\n",
            "5321/5321 [==============================] - 6s 1ms/step - loss: 0.7023 - mse: 0.7023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feed0271390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW4SEP8kT2ls"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EJDoix_7JU61"
      },
      "source": [
        "### Evaluate the model\n",
        "- Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HdH8pYBIjHGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "469612bb-564a-4450-e2d8-0447f137b865"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5321/5321 [==============================] - 5s 961us/step - loss: 0.7006 - mse: 0.7006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJc1bPQvh8yL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "67ae488b-89e7-4949-82ee-87b8249692b2"
      },
      "source": [
        "print(model.metrics_names)\n",
        "print(results)   "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'mse']\n",
            "[0.7005979418754578, 0.7005979418754578]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hUpDD74Xjh01"
      },
      "source": [
        "### Manual predictions\n",
        "- Test the predictions on manual inputs\n",
        "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler\n",
        "- Example of manual input: [123.430000,\t122.30999, 116.250000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fvuH-c31lLiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9fcaab0d-3600-4c03-ef63-09dd49e5c99f"
      },
      "source": [
        "manual_test = scaler.transform([[123.430000, 122.30999, 116.250000]])\n",
        "\n",
        "y_pred = model.predict(manual_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[119.75714]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4WH1Pr4KQlCh"
      },
      "source": [
        "# Build a DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "74cQBsi5QlCw"
      },
      "source": [
        "### Collect Fashion mnist data from tf.keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVWy0oDTr2Kj",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "no7aWYZyQlC1"
      },
      "source": [
        "### Change train and test labels into one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UX6otc4wQlC2",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjNrRTdoQlC5"
      },
      "source": [
        "### Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CDJ9DHVNQlC7"
      },
      "source": [
        "### Initialize model, reshape & normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCDQs_g1QlC8",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kBGwTTilQlDD"
      },
      "source": [
        "### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IXbfpfOzQlDF",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5I8f5otcQlDJ"
      },
      "source": [
        "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZkvKymSd0Sr",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6M4K7s7KY0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSiMhJPpk3GO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}